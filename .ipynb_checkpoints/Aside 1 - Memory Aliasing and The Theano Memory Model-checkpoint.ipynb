{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# (Aside:) Memory Aliasing and The Theano Memory Model"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Theano improves its performance by aggressively resuing memory wherever it can. It is therefore imperative that we understand\n",
      "how exactly Theano aliases buffers - to ensure that our program is both correct and efficient. \n",
      "\n",
      "#### The Memory Model: Two Spaces\n",
      "TL;DR - Theano manages it's own pool of memory and keeps track of changes made to this pool. \n",
      "\n",
      "+  Theano manages it's own memory space, which typically doesn't overlap with the memory of normal python variables that non Theano code creates  \n",
      "\n",
      "+  Theano's functions only modify buffers that are in Theano's memory space.   \n",
      "\n",
      "+  Theano's memory space includes the buffers allocated to store shared variables and the temporaries used to evaluate functions\n",
      "\n",
      "+  Physically, Theano's memory may be spread across the host, a GPU device and possibly in the future, spread across multiple remote machines.   \n",
      "\n",
      "+  The memory allocated for a shared variable buffer is unique. It is never aliased to another shared variable.   \n",
      "\n",
      "+  Theano's managed memory is constant while Theano functions are not running and Theano's library code is not running.   \n",
      "\n",
      "+  The default behavior for a function is to return user-space values for outputs and to expect user-space values for inputs  \n",
      "\n",
      "+  The distinction between Theano-managed memory and user-managed memory can be broken down by some Theano functions \n",
      "(e.g. <code>shared</code>, <code>get_value</code> and the constructors for 'in' and 'out') by using a <code>borrow = True</code> flag . \n",
      "\n",
      "+ Althought the point above makes the program faster by allowing it to avoid copy operations, risky bugs might be introduced\n",
      "in the program by doing so (by aliasing memory). "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 1. Borrowing when creating shared variables.  \n",
      "\n",
      "A <code> borrow </code> argument can be passed to the shared variable constructor. By default and equivalently when setting <code> borrow = False </code> , the shared variable that we create gets a __deep copy__ of the object in question (here, <code> np_array </code>) - this has the effect that any change made directly to the object (<code> np_array </code>) will have no effect on the shared variable. Go though (meticulously) the example below. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import theano\n",
      "np_array = np.ones(3, dtype='float32') #np_array is an array of ones (1x3)\n",
      "\n",
      "s_default = theano.shared(np_array) #This makes a deep copy - this is the default behavior\n",
      "s_false   = theano.shared(np_array, borrow=False) #This is superflous. 'False' is the default behavior\n",
      "s_true    = theano.shared(np_array, borrow=True) #Aliases the original object (np_array). "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "Let's now play with np_array and see what effect it has on the three shared variables"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np_array += 1 #np_array now becomes an array of 2's (1x3)\n",
      "\n",
      "s_default.get_value() #Since the default behavior was to make a deep copy, this prints the 1x3 ones array\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "array([ 1.,  1.,  1.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_false.get_value() #Since we explicitly (albeit superflously) asked to make a deep copy, this prints a 1x3 too"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([ 1.,  1.,  1.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s_true.get_value() #But here, since we set borrow=True, np_array was aliased and this prints the changed np_array"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "array([ 2.,  2.,  2.], dtype=float32)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Notes:   \n",
      "\n",
      "* If this code is run on a CPU as the device, the changes we make to <code>np_array</code> will show up immediately on <code> s_true.get_value()</code> because Numpy arrays are mutable and s_true is using the Numpy array <code>np_array</code> as it's internal buffer.    \n",
      "\n",
      "* It should however be noted that this aliasing of <code>np_array</code> and <code>s_true</code> is not guaranteed to occur and may occur temporarily if it occurs at al\n",
      "\n",
      "- It is __not guaranteed__ to occur because if Theano is running on a GPU then the <code>borrow</code> flag has __no effect__!\n",
      "\n",
      "- It may __occur temporarily__ because if we call a function that modifies the value of <code>s_true</code>, the aliasing relationship *may or may not* be broken. This is because the function is allowed to modify the shared variable (<code>s_true</code>) by either modifying the buffer that <code>s_true</code> uses (which preserves this aliasing) or by changing which buffer (<code>s_true</code>) points to (which will terminate this aliasing). \n",
      "\n",
      "#### The Moral of the Story:\n",
      "\n",
      "* It's a safe practice and a good idea to use <code>borrow = True</code> in a shared variable constructor when the shared variable stands for a large object (in terms of memory footprint) - in which case, creating copies of this object isn't something you really want to do. \n",
      "\n",
      "* It is not a reliable technique to use <code>borrow=True</code> to modify shared variables through side-effects because with some devices (e.g. GPU devices), this may not work. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## 2. Borrowing when accessing the values of shared variables. \n",
      "\n",
      "### 2.a. Retrieving the value of a shared variable"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A <code>borrow</code> can also be used to specify how the value of a shared variable is retrieved.  \n",
      "\n",
      "When <code>borrow=False</code> is passed to <code>get_value</code> (<code>borrow=False</code> is also the default value), it means that the return value may not be aliased to any part of Theano's internal memory. When <code>borrow=True</code> it means that the return value *might* be aliased to Theano's internal memory. But both these calls might end up creating copies of the internal memory. \n",
      "\n",
      "The reason that <code>borrow=True</code> might create a copy of the internal memory is because Theano might lay out a shared varible in memory using an internal representation that you do not expect. When you create a shared variable by passing a Numpy array for example, then <code>get_value()</code> might return a Numpy array too - this is how Theano can make the GPU use transparent. (Note on 'transparent use' below). But when you are using a GPU (or perhaps in the future, remote machines), then <code>numpy.ndarray</code> isn't the internal representation of your data. If you really want Theano to return the internal representation and to never make a copy, you can use the <code>return_internal_type=True</code> argument to <code>get_value</code> - it will never typecase the internal object (which means that the return happens in constant time) but might return a different datatype than the one you passed to it (depending on the compute device, the dtype of the Numpy Array etc). \n",
      "\n",
      "For a shared variable's <code>get_value()</code> function, the combination of *return_internal_type=True* and <code>borrow=True</code> is guarantees that a copy is not made"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "s = theano.shared(np_array)\n",
      "v_false = s.get_value(borrow=False) #The default behavior is 'false'. \n",
      "v_true  = s.get_value(borrow=True) \n",
      "print(v_false) #If this code were running on a GPU then these might've still printed..\n",
      "print(v_true) #the same thing - read the paragraph above!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.  2.  2.]\n",
        "[ 2.  2.  2.]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "v_internal = s.get_value(borrow=True, return_internal_type=True)\n",
      "print(v_internal) #Since this code is running on a CPU, it prints the same thing! "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ 2.  2.  2.]\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to use the <code> borrow = False </code> in conjunction with the <code>return_internal_type=True</code> argument. This would return a *deep copy* of the internal object - something that you would do for internal debugging and not typically for practical use. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Note: Theano's transparancy policy\n",
      "\n",
      "When the <code>get_value()</code> method is used, Theano, as a policy, always returns, by default, the same object type that it recieved when the shared variable was created. \n",
      "\n",
      "So let's say that you manually created data on the GPU and created a shared variable on the gpu with this data, <code>get_value</code> will always return GPU data even when the <code>return_internal_type=False</code> flag is set. \n",
      "\n",
      "#### The Moral of the Story\n",
      "\n",
      "* Use <code>get_value(borrow=True)</code> when your code doesn't modify the return value - it's safe and sometimes can be much faster  \n",
      "\n",
      "* __ Do not __ use <code>get_value(borrow=True)</code> to modify a shared variable by side effects because it makes your program device dependent. Modification of GPU variables through this sort of side effect is impossible. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2.b. Assigning the value of a shared variable. \n",
      "\n",
      "The __set_value__ of a shared variable can also accept a <code>borrow=True</code> argument. \n",
      "The semantics are __ similar to those associated with creating a new shared variable __:\n",
      "\n",
      "* <code> borrow = False </code> is the default behavior\n",
      "\n",
      "* <code> borrow = True </code> means that theano __ may reuse __ the buffer you provide as the internal storage for the variable. \n",
      "\n",
      "A standard pattern for manually updating the value of a shared variable is as follows:"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "s.set_value(some_inplace_function(s.get_value(borrow=True)),borrow=True)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above works irrespective of the computing device and performs as fast as an in-place update. \n",
      "Here's why it is guaranteed to work and a breakdown of the steps involved:\n",
      "\n",
      "* <code>some_inplace_function</code> tries to modify (in place, duh!) the data stored in the buffer returned by \n",
      "<code>s.get_value(borrow=True)</code> returns. The aim of setting the <code>borrow=True</code> flag in the *get_value* method is to modify the data while maitaining the aliasing to Theano's internal memory - remember, Theano doesn't guarantee that it won't return a copy instead. \n",
      "\n",
      "* <code>s.get_value(borrow=True)</code>  tries to get the value of 's' without making a copy. Since this isn't guaranteed to happen, there is a chance that it returns a copy of the buffer (data) and the <code>some_inplace_function</code> modifies this value (instead of modifying the original buffer). \n",
      "\n",
      "* The *set_value* with the <code>borrow=True</code> tells theano that it may reuse the buffer that you passed to it as the interal storage for that variable - thus effectively make the copy of s (if a copy is returned by get_value), the new  internal storage for 's'. \n",
      "\n",
      "##### TODO: Figure out how garbage collection works in Theano - the knowledge of which will allow you to figure out what happens to the original buffer in the case when get_value makes a copy!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Tips for using shared variables on GPU's:\n",
      "\n",
      "When shared variables are allocated on GPU's , making transfers to and from GPU memory can be expensive. \n",
      "The tips below ensure fast and efficient use of GPU memory and bandwidth. \n",
      "\n",
      "* Prior to Theano 0.3.1, <code> set_value</code> did not work in-place on the GPU. What this meant was that Theano would allocate memory on the GPU before the old memory was released. In the case that you were running near the limits of GPU memory, this could cause you to run out of GPU memory unnecessarily. \n",
      "\n",
      "   __solution__: update to a newer version of Theano\n",
      "   \n",
      "* If you are going to swap several chunks of data in and out of a shared variable repeatedly, you want to try and\n",
      "reuse the memory that you allocated the first time if possible - it is both faster and more memory  efficient. \n",
      "\n",
      "   __solution__: upgrade to a newer version of Theano and consider padding your source data make sure that every chunk is the same size. \n",
      "  \n",
      "* Current GPU copying routines only support the copying of contiguous memory. So theano must make the value you provide C-contiguous (explained below) before copying it and this might entail making an extra copy of the data on the host. \n",
      "\n",
      "  __solution__: make sure that the value that you assign to a <code>CudaNdarraySharedVariable</code> is __already__  C-contiguous. \n",
      "  \n",
      "-------------------------------------------------------------------\n",
      "> #### Concept: C-Contiguous [Source:](http://docs.cython.org/src/userguide/memoryviews.html#brief-recap-on-c-fortran-and-strided-memory-layouts)\n",
      "> The simplest way of laying out data in memory might be a 'C contiguous array'. This is the default in Numpy\n",
      "> and Cython arrays. C-Contiguous means that the array data is continous in memory (see example below) and that neighboring elements in the first dimension are furthest apart in memory and neighboring elements in the last dimension are the closest together. For example, in numpy:\n",
      "\n",
      "> [Documentation for dtype = S1](http://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr = np.array([['a','b','c'],['d','e','f']],dtype=\"S1\") #S1 means strings of length '1'. "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "> Here, <code>arr[0,0]</code> and <code>arr[0,1]</code> are one byte apart in memory. Whereas <code>arr[0,0]</code> and <code>arr[1,0]</code> are 3 bytes apart in memory. i.e. Since the array is a 2D array, neighboring elements in the first dimension (the neighboring elements in rows of the array) are the closest together, whereas neighboring elements in the last dimension (here, the second dimension - i.e. neighboring elements in the columns of the array) are furthest apart. \n",
      "\n",
      "> This leads to the idea of strides. Each axis of the array has a stride length, which is basically the number of bytes that you need to go from one element to the other. Here, the strides are:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "arr.strides #be wary of the order of the output. (3,1) means that to go from one element in one row\n",
      "            #..to the corresponding element in the next row, you'll need a stride '3' bytes long"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "(3, 1)"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "----------------------------------------------------------------------- "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. Borrowing when constructing function objects\n",
      "\n",
      "A borrow argument can also be provided to the <code>In</code> and <code>Out</code> objects that control how <code>theano.function</code> handles its arguments and return values. \n",
      "\n",
      "The __default__ value is to __NOT__ borrow either the output or the input. \n",
      "\n",
      "__ Borrowing an input__ means that Theano will treat that argument that you provide as if it were one part of Theano's pool of temporaries. This also means that that the input you provide might be reused as a buffer and overwritten during the course of computation of other variables in the course of evaluation that function (for example in the function __f__ below)\n",
      "\n",
      "__ Borrowing an output__ means that Theano won't bother allocation a fresh output buffer every time you call the function. It will possibly reuse the same one as that of the previous function call and overwrite the old content instead. Consequently it may overwrite old return values throught side effect. Those return values may also be overwritten in the course of evaluation another compiled function (for example, the output might be aliased to another shared variable). So __be careful__ when using a borrowed return - use the value right away before calling any more Theano functions. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = theano.tensor.matrix()\n",
      "y = 2*x\n",
      "f = theano.function([theano.In(x,borrow=True)],[theano.Out(y,borrow=True)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It is also possible to add a <code>return_internal_type</code> flag to the <code>Out</code> variable which has the same interpretation as the <code>return_internal_type</code> flag to the shared variable's <code>get_value</code> function. But unlike <code>get_value()</code> the combination of <code>return_internal_type=True</code> and <code>borrow=True</code> arguments to <code>Out()</code> are not guaranteed to avoid copying the output value. They are just hints that give more flexibility to the compilation and optimization of the graph. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### Moral of the story:\n",
      "\n",
      "* If an __ input 'x'__ to a function is no longer required after the function returns and you would like to make it available to Theano as additional workspace, then consider making it with __ In(x,borrow=True)__ . It may make the function faster and reduce it's memory requirement. \n",
      "\n",
      "* When a __ return value 'y'__ is large (in terms of memory footprint), and you only need to read from it once (that one time being immediately after it's returned), then consider using __Out(y,borrow=True)__  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}